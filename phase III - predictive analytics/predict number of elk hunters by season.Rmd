---
title: "Predict Number of Future Elk Hunters per Unit Season"
author: "Pierre Sarnow"
output:
  html_notebook:
    toc: yes
    toc_float: false
    toc_depth: 6
    theme: yeti
    hightlight: default
    code_folding: none
---


***
## Description
Use historical draw results, and number of hunters to train a model we can use to 
predict the number of hunters in future years. I would like to compare this to the results
we generated by grouping the seasons together. 


*__NOTICE__ that I am only looking at the general rifle hunting seasons on public land. There are also 
hunters for Archery, Muzzleloader, Private Land, Ranching for Wildlife, etc.*

***
## Setup
Load required libraries for wrangling data, charting, and mapping
```{r}
library(plyr,quietly = T) # data wrangling
library(dplyr,quietly = T) # data wrangling
library(ggplot2, quietly = T) # charting
library(ggthemes,quietly = T) # so I can add the highcharts theme and palette
library(scales,quietly = T) # to load the percent function when labeling plots
library(caret,quietly = T) # classification and regression training
library(foreach,quietly = T) # parallel processing to speed up the model training
library(doMC,quietly = T) # parallel processing to speed up the model training
library(lubridate,quietly = T) # for timing models
```

Set our preferred charting theme
```{r}
theme_set(theme_minimal()+theme_hc()+theme(legend.key.width = unit(1.5, "cm")))
``` 

Run script to get hunter data
```{r}
source('~/_code/colorado-dow/datasets/Colorado Elk Harvest Data.R', echo=F)
```

Table of the harvest data
```{r}
head(COElkRifleAll)
```


Run script to get draw data
```{r}
source('~/_code/colorado-dow/datasets/Elk Drawing Summaries.R', echo=F)
```

Table of the data
```{r}
head(COElkDrawAll)
```

source geodata
```{r}
source('~/_code/colorado-dow/datasets/Colorado GMUnit and Road data.R', echo=F)
```

Take a peak at the boundary data
```{r}
head(Unitboundaries2)
```

Set to predictive analytics directory
```{r}
setwd("~/_code/colorado-dow/phase III - predictive analytics")
```
***
### Organize data
Will start by grouping all of the seasons together, and modeling the number of hunters per Year and Unit

Group Draw results data by Year and Unit
```{r}
COElkDraw_Unit <- summarise(group_by(COElkDrawAll,Year,Unit,Season),
                       Quota = sum(Orig_Quota,na.rm = T),
                       Drawn = sum(Chcs_Drawn,na.rm = T))
```

Appropriate field classes for model training
```{r}
COElkDraw_Unit$Year <- as.numeric(COElkDraw_Unit$Year)
```

Group Hunter data by Year and Unit
```{r}
COElkHunters_Unit <- summarise(group_by(COElkRifleAll,Year,Unit,Season),
                          Hunters = sum(c(Hunters.Antlered,Hunters.Antlerless,Hunters.Either),na.rm = T))

COElkHunters_Unit$Year <- as.numeric(COElkHunters_Unit$Year)
```

Join in Hunter and Draw data together
```{r}
COElkHunters_Unit <- left_join(COElkHunters_Unit, COElkDraw_Unit, by = c("Year","Unit","Season"))
```

Replace the draw data that don't have entries with 0
```{r}
COElkHunters_Unit$Drawn[is.na(COElkHunters_Unit$Drawn)] <- 0
COElkHunters_Unit$Quota[is.na(COElkHunters_Unit$Quota)] <- 0
```

Split into train and test sets. Will use 75% of the data to train on. 

```{r}
COElkHunters_Unit <- mutate(group_by(COElkHunters_Unit,Unit),
                       numentries = n())
COElkHunters_Unit <- filter(COElkHunters_Unit, numentries >= 3)
COElkHunters_Unit$UnitYearSeason <- paste(COElkHunters_Unit$Unit, COElkHunters_Unit$Year,COElkHunters_Unit$Season)

traindata2 <- COElkHunters_Unit %>% group_by(Unit) %>% sample_frac(size = .75, replace = F)
testdata2 <- COElkHunters_Unit[!COElkHunters_Unit$UnitYearSeason %in% traindata2$UnitYearSeason,]

COElkHunters_Unit <- select(COElkHunters_Unit, -UnitYearSeason, -numentries)

traindata2 <- select(traindata2, -UnitYearSeason, -numentries)
testdata2 <- select(testdata2, -UnitYearSeason, -numentries)
```

Save off for importing into AzureML
```{r}
write.csv(COElkHunters_Unit,file = "~/_code/colorado-dow/datasets/COElkHunters_Unit.csv",row.names = F)
```
### Data Visualization
notice that the number of hunters data is skewed.
```{r fig.width=10}
ggplot(COElkHunters_Unit, aes(Hunters)) + 
  geom_density() +
  xlab("Hunters in Unit") +
  ylab("Number of Units") +
  theme(axis.text.y = element_blank()) +
  labs(title="Distribution of Hunters in each Unit", subtitle="2006-2017", caption="source: cpw.state.co.us")

```


A general rule of thumb to consider is that skewed data whose ratio of the highest value to the 
lowest value is greater than 20 have significant skewness. Also, the skewness statistic can be 
used as a diagnostic. If the predictor distribution is roughly symmetric, the skewness values 
will be close to zero. As the distribution becomes more right skewed, the skewness statistic 
becomes larger. Similarly, as the distribution becomes more left skewed, the value becomes negative.
Replacing the data with the log, square root, or inverse may help to remove the skew.

Example of how BoxCox can redistribute the data
```{r}
preProcValues2 <- preProcess(as.data.frame(traindata2), method = "BoxCox")
trainBC <- predict(preProcValues2, as.data.frame(traindata2))
```

```{r fig.width=10}
ggplot(trainBC, aes(Hunters)) + 
  geom_density() +
  xlab("BoxCox Hunters in Unit") +
  ylab("Number of Units") +
  theme(axis.text.y = element_blank()) +
  labs(title="BoxCox Distribution of Hunters in each Unit", subtitle="2006-2017", caption="source: cpw.state.co.us")
```
caret has a preproccess function for correcting for skewness 'BoxCox', we will need to be sure to
look at using this function in the training models.

***
## Model Building

### Model Training Methods
Loop through possible methods, utilizing the quicker 'adaptive_cv' parameter search from caret.
Consider scripting this into AzureML to make it run much faster, though there is more setup and errors to 
control for

```{r}
quickmethods <- c("lm",'svmLinear',"svmRadial","knn","cubist","kknn","glm.nb")

step1_all_Unit <- NULL
for (imethod in quickmethods) {
  step1_Unit <- NULL
  start <- now()
  
  # if (imethod == "lm") {
  #   controlmethod <- "repeatedcv"
  # } else {controlmethod <- "adaptive_cv"}
  controlmethod <- "repeatedcv"
  fitControl <- trainControl(
    method = controlmethod,
    # search = 'random',
    number = 4,
    repeats = 4,
    allowParallel = TRUE,
    summaryFunction = defaultSummary)
  
  registerDoSEQ()
  registerDoMC(cores = 6)
  
  HuntersModel_1_Unit = train(Hunters ~ ., data = traindata2,
                         method = imethod,
                         tuneLength = 15,
                         trControl = fitControl)
  
  HuntersModel_1_Unit
  
  # measure performance
  predictdata <- predict(HuntersModel_1_Unit, testdata2)
  
  step1_Unit$method <- imethod
  step1_Unit$RMSE <- postResample(pred = predictdata, obs = testdata2$Hunters)[1]
  step1_Unit$duration <- now() - start
  step1_Unit <- as.data.frame(step1_Unit)
  step1_all_Unit <- rbind(step1_all_Unit,step1_Unit)
}
```
View Results, and compare to previous first models that did not expand to Seasons
```{r}
step1_all
step1_all_Unit
```
The performance RMSE metric is certainly improved when including the Seasonal grouping.
Lets take the best method, and see if it is visually reasonable while also charting without Seasons.

### Predictions using best Season model
Build model
```{r}
controlmethod <- "repeatedcv"
  fitControl <- trainControl(
    method = controlmethod,
    # search = 'random',
    number = 4,
    repeats = 4,
    allowParallel = TRUE,
    summaryFunction = defaultSummary)
  
registerDoSEQ()
registerDoMC(cores = 6)
  
HuntersModel_1_Unit = train(Hunters ~ ., data = COElkHunters_Unit,
                         method = "svmRadial",
                         # preProc = c("center","scale"), 
                         tuneLength = 15,
                         trControl = fitControl)
  
HuntersModel_1_Unit
```
Predict Hunter for next year, 2018
```{r}
# Get list of Units and Seasons that will have data
COElkHunters2018_Unit <- COElkHunters_Unit
COElkHunters2018_Unit$Unit_Season <- paste(COElkHunters2018_Unit$Unit,COElkHunters2018_Unit$Season)
COElkHunters2018_Unit <- as.data.frame(unique(COElkHunters2018_Unit$Unit_Season))
colnames(COElkHunters2018_Unit) <- "Unit_Season"
# Fill in missing Units and Seasons per unique Unit_Seasons
COElkHunters2018_Unit$Unit <- str_extract(COElkHunters2018_Unit$Unit_Season,"[:alnum:]+(?=[:blank:])")
COElkHunters2018_Unit$Season <- str_extract(COElkHunters2018_Unit$Unit_Season,"(?<=[:blank:])[:alnum:]+")
COElkHunters2018_Unit <- select(COElkHunters2018_Unit, -Unit_Season)
COElkHunters2018_Unit$Year <- 2018
# Draw data for 2018
COElkDraw_Unit2018 <- filter(COElkDraw_Unit,Year==2018)

# A left join will autofill missing draw data with NAs, but will retain the full list of Unit Seasons
COElkHunters2018_Unit <- left_join(COElkHunters2018_Unit,COElkDraw_Unit2018)

# Replace the draw data that don't have entries with 0
COElkHunters2018_Unit$Drawn[is.na(COElkHunters2018_Unit$Drawn)] <- 0
COElkHunters2018_Unit$Quota[is.na(COElkHunters2018_Unit$Quota)] <- 0

# Only use the fields that were included in the model
COElkHunters2018_Unit <- COElkHunters2018_Unit[, colnames(COElkHunters2018_Unit) %in% c("Unit","Season",HuntersModel_1_Unit$coefnames)]
# Use trained model to predict Hunters
COElkHunters2018_Unit$Hunters <- round(predict(HuntersModel_1_Unit, COElkHunters2018_Unit))

COElkHunters2018_Unit$Hunters[COElkHunters2018_Unit$Hunters<0] <- 0
```

Label and Join models together for comparisons
```{r}
# Load first model without Seasons
load("~/_code/colorado-dow/datasets/COElkHunters2018.RData")
Hunterscompare <- rbind.fill(COElkHunters,COElkHunters2018)
Hunterscompare$modeldata <- "Without Seasons"

Hunterscompare_Season <- rbind.fill(COElkHunters_Unit,COElkHunters2018_Unit)
Hunterscompare_Season <- summarise(group_by(Hunterscompare_Season,Year,Unit),
                                   Hunters = sum(Hunters))
Hunterscompare_Season$modeldata <- "Seasons"

Hunterscompare <- rbind.fill(Hunterscompare,Hunterscompare_Season)

```
```{r}
# Group Units
HunterscompareStatewide <- summarise(group_by(Hunterscompare,Year,modeldata),
                                   Hunters = sum(Hunters))
```

```{r fig.width=10}
ggplot(HunterscompareStatewide, aes(Year,Hunters,group=modeldata,fill=modeldata)) +
  geom_bar(position="dodge",stat="identity") +
  coord_cartesian(ylim = c(130000,155000)) +
  scale_fill_hc() +
  labs(title="Statewide Elk Hunters", caption="source: cpw.state.co.us")
```


#### Hunters Statewide by Season and Year
```{r fig.width=10}
Hunters_Season <- rbind.fill(COElkHunters_Unit,COElkHunters2018_Unit)
ggplot(Hunters_Season, aes(Year,Hunters,group=Season,fill=Season)) +
  geom_bar(position="dodge",stat="identity") +
  # coord_cartesian(ylim = c(130000,155000)) +
  scale_fill_hc() +
  labs(title="Statewide Elk Hunters", caption="source: cpw.state.co.us")
```

#### Hunters in Unit 77
```{r fig.width=10}
Hunters_Season_77 <- filter(Hunters_Season, Unit == "77")
ggplot(Hunters_Season_77, aes(Year,Hunters,group=Season,fill=Season)) +
  geom_bar(position="dodge",stat="identity") +
  # coord_cartesian(ylim = c(130000,155000)) +
  scale_fill_hc() +
  labs(title="Statewide Elk Hunters", caption="source: cpw.state.co.us")
```


### Compare to the Draw Data (Quota, Drawn)
```{r fig.width=10}
Data_Season_77 <- gather(Hunters_Season_77,"Field",Amount,Hunters,Quota,Drawn)
ggplot(Data_Season_77, aes(Season,Amount,fill=Field,group=Field)) +
  # geom_point() +
  # geom_line() +
  facet_grid(. ~ Year) +
  geom_bar(position="dodge",stat="identity") +
  # coord_cartesian(ylim = c(130000,155000)) +
  scale_fill_hc() +
  labs(title="Statewide Elk Hunters", caption="source: cpw.state.co.us")
```
```{r fig.width=10}
ggplot(Data_Season_77, aes(Year,Amount,color=Field,group=Field)) +
  # geom_point() +
  geom_line() +
  facet_grid(Season ~ .,scales = 'free') +
  # geom_bar(position="dodge",stat="identity") +
  # coord_cartesian(ylim = c(130000,155000)) +
  scale_color_hc() +
  labs(title="Statewide Elk Hunters", caption="source: cpw.state.co.us")
```


## Keep going by creating models for hunters per year, unit and season?
I believe the results appear reasonable.

We can further identify better models and tune them.
But right now we will proceed with the last trained model.... revisiting after the
project is more complete.

Save off so we don't have to recreate the model everytime we want the results
```{r}
FinalHuntersSeasonmodel <- HuntersModel_1_Unit
```
```{r}
save(FinalHuntersSeasonmodel, file = "~/_code/colorado-dow/datasets/FinalHuntersSeasonmodel.RData")
```

```{r}
COElkHunters2018_Season <- COElkHunters2018_Unit
save(COElkHunters2018_Season,file="~/_code/colorado-dow/datasets/COElkHunters2018_Season.RData")
```


